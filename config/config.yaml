# Data settings
data:
  dataset_path: "dataset/cleaned_dataset_100k.csv"
  source_max_len: 37
  target_max_len: 43
  pad_token: "<pad>"

# Model settings
model:
  num_layers: 6
  d_model: 1024
  num_heads: 16  # Number of heads
  d_ff: 2048
  src_vocab_size: 96038  # Vocabulary size for source
  tgt_vocab_size: 96038  # Vocabulary size for target
  max_len: 43  # Maximum sequence length (or greater if needed)
  dropout_rate: 0.2

# Training settings
training:
  warmup_steps: 4000
  batch_size: 32
  learning_rate: 0.000001
  epochs: 200
  checkpoint_dir: "checkpoints/"
